import{_ as e,c as s,o as t,a0 as i}from"./chunks/framework.DWF-bbW5.js";const l="/gaius-blog/assets/model-list.BjkSVF35.png",p="/gaius-blog/assets/first.BBs5LuYQ.png",n="/gaius-blog/assets/chatboxCfg.D4YXX1my.png",h="/gaius-blog/assets/qa.DpN_QT0E.png",o="/gaius-blog/assets/setup-error.Cu4UJYAY.png",x=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"record/model/setup-deepseek.md","filePath":"record/model/setup-deepseek.md"}'),r={name:"record/model/setup-deepseek.md"};function d(c,a,k,g,m,b){return t(),s("div",null,a[0]||(a[0]=[i('<h3 id="引言" tabindex="-1">引言 <a class="header-anchor" href="#引言" aria-label="Permalink to &quot;引言&quot;">​</a></h3><p>在人工智能飞速发展的今天，大型语言模型（LLM）已成为技术领域的核心工具。然而，依赖云端服务可能存在隐私泄露、网络延迟等问题。本地部署大模型既能保障数据安全，又能实现离线高效推理。本文将手把手教你通过 Ollama 框架在本地部署 DeepSeek 大模型，并搭配 ChatBox 桌面客户端实现可视化交互，全程无需复杂代码！</p><h3 id="一、准备工作" tabindex="-1">一、准备工作 <a class="header-anchor" href="#一、准备工作" aria-label="Permalink to &quot;一、准备工作&quot;">​</a></h3><p><strong>1.硬件要求</strong></p><p>内存：建议 ≥ 16GB（7B 模型需 8GB 以上，更大模型需更高配置）。</p><p>存储：至少 20GB 可用空间（模型文件通常为 5GB~20GB）。</p><p>操作系统：支持 Windows / macOS / Linux。</p><p><strong>2.实验机配置</strong></p><p>处理器：Intel i5-12490F</p><p>显卡：AMD Radeon RX 7800 XT</p><p>内存：32GB</p><p>存储：1TB SSD</p><p>操作系统：Windows 11</p><p><strong>3.软件依赖</strong></p><p>安装 Ollama：跨平台的大模型本地化工具。</p><p>下载 ChatBox：开源的 AI 桌面客户端，支持 Ollama 连接。</p><h3 id="二、安装-ollama-并部署-deepseek-模型" tabindex="-1">二、安装 Ollama 并部署 DeepSeek 模型 <a class="header-anchor" href="#二、安装-ollama-并部署-deepseek-模型" aria-label="Permalink to &quot;二、安装 Ollama 并部署 DeepSeek 模型&quot;">​</a></h3><h5 id="步骤-1-安装-ollama" tabindex="-1">步骤 1：安装 Ollama <a class="header-anchor" href="#步骤-1-安装-ollama" aria-label="Permalink to &quot;步骤 1：安装 Ollama&quot;">​</a></h5><p>Windows/macOS：直接<a href="https://github.com/ollama/ollama/releases" target="_blank" rel="noreferrer">下载安装包</a>，双击运行。</p><p>Linux：一行命令快速安装：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">curl</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -fsSL</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://ollama.ai/install.sh</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> sh</span></span></code></pre></div><h5 id="步骤-2-拉取-deepseek-模型" tabindex="-1">步骤 2：拉取 DeepSeek 模型 <a class="header-anchor" href="#步骤-2-拉取-deepseek-模型" aria-label="Permalink to &quot;步骤 2：拉取 DeepSeek 模型&quot;">​</a></h5><p>Ollama 官方模型库已集成多版本 DeepSeek 模型（需确认模型名称）： <img src="'+l+`" alt="支持模型列表"></p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 示例：拉取 DeepSeek R1 14B 版本（具体名称以官方仓库为准）</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> pull</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> deepseek-r1:14b</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 若模型未官方支持，可手动加载 GGUF 格式模型（需提前转换）</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> create</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> deepseek-custom</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ./Modelfile</span></span></code></pre></div><p>步骤 3：运行模型</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> deepseek-r1:14b</span></span></code></pre></div><p>首次运行：Ollama 会自动下载模型并加载到内存。</p><p>验证部署：输入简单问题测试响应，例如：</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span></span></span>
<span class="line"><span>&gt;&gt;&gt; 你好，请介绍一下 javascript 的特点。</span></span></code></pre></div><p><img src="`+p+'" alt="alt text"></p><h3 id="三、使用-chatbox-实现可视化交互" tabindex="-1">三、使用 ChatBox 实现可视化交互 <a class="header-anchor" href="#三、使用-chatbox-实现可视化交互" aria-label="Permalink to &quot;三、使用 ChatBox 实现可视化交互&quot;">​</a></h3><p>ChatBox 提供类似 ChatGPT 的友好界面，支持多会话管理和历史记录。</p><h5 id="步骤-1-安装-chatbox" tabindex="-1">步骤 1：安装 ChatBox <a class="header-anchor" href="#步骤-1-安装-chatbox" aria-label="Permalink to &quot;步骤 1：安装 ChatBox&quot;">​</a></h5><p>前往 GitHub Release 页面，<a href="https://github.com/Bin-Huang/chatbox/releases" target="_blank" rel="noreferrer">下载</a>对应系统的安装包。</p><h5 id="步骤-2-配置-ollama-连接" tabindex="-1">步骤 2：配置 Ollama 连接 <a class="header-anchor" href="#步骤-2-配置-ollama-连接" aria-label="Permalink to &quot;步骤 2：配置 Ollama 连接&quot;">​</a></h5><p>打开 ChatBox，进入 设置 → 模型设置。</p><p>在 API 地址 中输入 Ollama 服务地址：<code>http://localhost:11434。</code></p><p>选择已下载的模型 <strong>deepseek-r1:14b</strong>。 <img src="'+n+'" alt="chatBox配置"></p><h5 id="步骤-3-开始对话" tabindex="-1">步骤 3：开始对话 <a class="header-anchor" href="#步骤-3-开始对话" aria-label="Permalink to &quot;步骤 3：开始对话&quot;">​</a></h5><p>输入问题（支持 Markdown 和代码块）： <img src="'+h+'" alt="问答"></p><h3 id="四、常见问题解决" tabindex="-1">四、常见问题解决 <a class="header-anchor" href="#四、常见问题解决" aria-label="Permalink to &quot;四、常见问题解决&quot;">​</a></h3><p><strong>1.模型下载失败</strong></p><p>方案：检查网络连接，尝试更换镜像源或使用代理。 当下载速度突然变慢时，可以尝试终止当前下载，重新下载。因为有数据缓存会接着继续下载。 <img src="'+o+'" alt="下载异常"></p><p><strong>2.推理速度慢</strong></p><p>方案：关闭其他占用内存的软件，或升级硬件配置。</p><h3 id="五、总结" tabindex="-1">五、总结 <a class="header-anchor" href="#五、总结" aria-label="Permalink to &quot;五、总结&quot;">​</a></h3><p>通过 Ollama + ChatBox 组合，即使非技术用户也能轻松在本地部署和体验大模型。DeepSeek 的高效推理能力结合 ChatBox 的直观交互，为学习、开发甚至内容创作提供了强大支持。</p><h4 id="参考链接" tabindex="-1">参考链接 <a class="header-anchor" href="#参考链接" aria-label="Permalink to &quot;参考链接&quot;">​</a></h4><p><a href="https://github.com/ollama/ollama" target="_blank" rel="noreferrer">Ollama 官方文档</a></p><p><a href="https://github.com/Bin-Huang/chatbox" target="_blank" rel="noreferrer">ChatBox GitHub 仓库</a></p><p><a href="https://www.deepseek.com/" target="_blank" rel="noreferrer">DeepSeek</a></p><p>立即动手，打造你的私人 AI 助手吧！ 🚀</p>',52)]))}const B=e(r,[["render",d]]);export{x as __pageData,B as default};
